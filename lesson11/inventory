# Please specify the ip addresses and connection settings for your environment
# The specified ip addresses will be used to listen by the cluster components.
# Attention! Specify private IP addresses so that the cluster does not listen a public IP addresses.
# For deploying via public IPs, add 'ansible_host=public_ip_address' variable for each node.

# "postgresql_exists='true'" if PostgreSQL is already exists and running
# "hostname=" variable is optional (used to change the server name)
# "new_node=true" to add a new server to an existing cluster using the add_pgnode.yml playbook

# In this example, all components will be installed on PostgreSQL nodes.
# You can deploy the haproxy balancers and the etcd or consul cluster on other dedicated servers (recomended).

# if dcs_exists: false and dcs_type: "etcd"

[all]
192.168.56.191 ansible_private_key_file=.vagrant/machines/xdb1/virtualbox/private_key
192.168.56.192 ansible_private_key_file=.vagrant/machines/xdb2/virtualbox/private_key
192.168.56.193 ansible_private_key_file=.vagrant/machines/xdb3/virtualbox/private_key



[etcd_cluster]  # recommendation: 3, or 5-7 nodes
192.168.56.191
192.168.56.192
192.168.56.193

# if dcs_exists: false and dcs_type: "consul"
[consul_instances]  # recommendation: 3 or 5-7 nodes
192.168.56.191 consul_node_role=server consul_bootstrap_expect=true consul_datacenter=dc1
192.168.56.192 consul_node_role=server consul_bootstrap_expect=true consul_datacenter=dc1
192.168.56.193 consul_node_role=server consul_bootstrap_expect=true consul_datacenter=dc1
#10.128.64.144 consul_node_role=client consul_datacenter=dc1
#10.128.64.145 consul_node_role=client consul_datacenter=dc2

# if with_haproxy_load_balancing: true
[balancers]
192.168.56.191
192.168.56.192
192.168.56.193
#10.128.64.144 new_node=true

# PostgreSQL nodes
[master]
192.168.56.191 hostname=xdb1 postgresql_exists=false

[replica]
192.168.56.192 hostname=xdb2 postgresql_exists=false
192.168.56.193 hostname=xdb3 postgresql_exists=false
#10.128.64.144 hostname=pgnode04 postgresql_exists=false new_node=true

[postgres_cluster:children]
master
replica

# if pgbackrest_install: true and "repo_host" is set
[pgbackrest]  # optional (Dedicated Repository Host)

[nginx_frontend]
192.168.56.194 ansible_private_key_file=.vagrant/machines/nginx1/virtualbox/private_key

# Connection settings
[all:vars]
ansible_connection='ssh'
ansible_ssh_port='22'
ansible_user='vagrant'
#ansible_ssh_pass='secretpassword'  # "sshpass" package is required for use "ansible_ssh_pass"
#ansible_ssh_private_key_file=
ansible_python_interpreter='/usr/bin/python3'  # is required for use python3

[pgbackrest:vars]
ansible_user='postgres'
ansible_ssh_pass='secretpassword'

